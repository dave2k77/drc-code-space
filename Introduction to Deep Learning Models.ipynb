{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446dd55c",
   "metadata": {},
   "source": [
    "# Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2f78d",
   "metadata": {},
   "source": [
    "### Load the required libraries, dataset and carry out preprocessing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7c643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 11:38:10.158412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/davianc/HADOOP/lib/native:\n",
      "2022-02-14 11:38:10.158441: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the TensorFlow Library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the MNIST Dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Load the data into training and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalise the training and test sets\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed53abb",
   "metadata": {},
   "source": [
    "### Explore the dataset using visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41d09f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf5bd1cc70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show an image from the dataset\n",
    "plt.imshow(x_train[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b254a",
   "metadata": {},
   "source": [
    "The first example in the training set is the image of a `5`. If we print this value, we see that the computational representation is a numpy `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a01508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# view the computational representation of the image.\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a76d5",
   "metadata": {},
   "source": [
    "### Create and train a sequential neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beeba0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 11:38:13.272326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/davianc/HADOOP/lib/native:\n",
      "2022-02-14 11:38:13.272354: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-14 11:38:13.272374: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (drc-02): /proc/driver/nvidia/version does not exist\n",
      "2022-02-14 11:38:13.272648: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2597 - accuracy: 0.9233\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1071 - accuracy: 0.9672\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0740 - accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf59ac6d60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sequential models\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(tf.keras.layers.Flatten()) # flatten the first layer\n",
    "\n",
    "# Create dense layers for the inner hidden layers with activation function\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "# Create the final layer with probabilistic activation function\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "# Compile the model with optimiser, loss function and metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1dd83",
   "metadata": {},
   "source": [
    "The training results show that the model is about 98% accurate with a loss of about 8%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a74c6",
   "metadata": {},
   "source": [
    "### Evaluate the loss function and accuracy score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79290bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9720\n",
      "loss: 0.08884605765342712, accuracy: 0.972000002861023\n"
     ]
    }
   ],
   "source": [
    "# test the model on the test data and extract the loss and accuracy values.\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"loss: {val_loss}, accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bb07d",
   "metadata": {},
   "source": [
    "On the test data, the model is about 97.0% accurate, experiencing a slight reduction in accuracy, and slight increase in loss (~9.0%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9506efc",
   "metadata": {},
   "source": [
    "### Save the model, reload it, and use it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb64d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 11:38:22.639366: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_num_reader.model/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model.save('test_num_reader.model')\n",
    "\n",
    "# reload the model into a new variable\n",
    "new_model = tf.keras.models.load_model('test_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4735f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.5767284e-10 5.2902632e-08 1.9992540e-06 ... 9.9996138e-01\n",
      "  1.6786579e-09 8.6941702e-07]\n",
      " [6.0253974e-08 1.0105975e-02 9.8980355e-01 ... 3.0248506e-09\n",
      "  1.2814756e-07 2.0510825e-08]\n",
      " [2.8465442e-07 9.9941468e-01 4.4954704e-05 ... 3.0811716e-04\n",
      "  1.2403079e-04 6.2811073e-06]\n",
      " ...\n",
      " [5.0820681e-08 2.2191699e-07 3.6665281e-08 ... 8.8562720e-06\n",
      "  1.7803317e-06 1.2868393e-04]\n",
      " [9.1368844e-07 1.6723429e-06 7.4550499e-08 ... 7.5590870e-06\n",
      "  1.7342929e-04 4.3273108e-08]\n",
      " [1.0176187e-06 2.0362148e-08 2.6419815e-07 ... 1.8142397e-10\n",
      "  2.0049359e-07 9.7753077e-09]]\n"
     ]
    }
   ],
   "source": [
    "# use the reloaded model to make predictions\n",
    "predictions = new_model.predict([x_test])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad974ce",
   "metadata": {},
   "source": [
    "The `predictions` variable stores probability distribution values in a `ndarray` for the predicted outcomes and so it is not quite useful to us in this format. To overcome this problem, we can use `numpy`'s `argmax()` function as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f95e64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# view the predicted value\n",
    "import numpy as np\n",
    "seventh_prediction = np.argmax(predictions[4])\n",
    "print(seventh_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe7b80",
   "metadata": {},
   "source": [
    "This tells us that the 3rd predicted value is a `4`. We can view the graphical representation to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c74a489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf18526d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the graphical representation of the predicted value\n",
    "plt.imshow(x_test[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
